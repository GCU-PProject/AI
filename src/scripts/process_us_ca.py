import json
import re
from datasets import load_dataset

# ================= ì„¤ì • =================
TARGET_PER_COUNTRY = 500
OUTPUT_FILE = 'laws_data.json'

COUNTRY_MAP = {'US': 1, 'CA': 2}

# ================= ë¡œì§ =================

def clean_text(text):
    if not text: return ""

    # 1. ì‹œìŠ¤í…œ í—¤ë” ë° ë³€í™˜ê¸° ë¡œê·¸ ì œê±°
    # "Online@...", "USCConverter" íŒ¨í„´ ì‚­ì œ
    text = re.sub(r'.*?Online@[\w\-]+\s+(yes|no)', '', text, flags=re.IGNORECASE)
    text = re.sub(r'.*?USCConverter\s+[\d\.]+', '', text, flags=re.IGNORECASE)

    # 2. ë¶ˆí•„ìš”í•œ í—¤ë”/í‘¸í„° ì œê±°
    text = re.sub(r'Title\s+\d+\s+USC.*', '', text)
    text = re.sub(r'Current through.*', '', text) # "Current through 117-49" ê°™ì€ ë²„ì „ ì •ë³´ ì‚­ì œ

    # 3. ëª©ì°¨ ì œê±°
    # "301.Title... 303.Title..."ê³¼ ê°™ì´ ìˆ«ìê°€ ë°˜ë³µí•´ì„œ ë‚˜ì˜¤ëŠ” íŒ¨í„´ ì œê±°
    if len(re.findall(r'\d{3,}\.[A-Z]', text)) > 3: 
        return ""

    # 4. ê°œì • ì´ë ¥ ìë¥´ê¸°
    cutoff_markers = [
        "Editorial Notes", "Statutory Notes", "git Historical and Revision", 
        "Amendments", "AMENDMENTS", "Repeals"
    ]
    for marker in cutoff_markers:
        if marker in text:
            text = text.split(marker)[0]

    # 5. ê³µë°± ë° íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
    text = re.sub(r'\s+', ' ', text).strip()
    text = text.lstrip(' ,.-:;')

    # 6. ë‚´ìš© ê²€ì¦: ë„ˆë¬´ ì§§ê±°ë‚˜(20ì ë¯¸ë§Œ), "Repealed"(íì§€ë¨)ë§Œ ìˆëŠ” ê²½ìš° ë²„ë¦¼
    if len(text) < 20 or "Repealed" in text[:50]:
        return ""

    return text

def get_title(text):
    """ë¯¸êµ­ ë²•ì „(US Code) íŠ¹í™” ì œëª© ì¶”ì¶œê¸°"""
    
    # íŒ¨í„´ 1: "Title 51â€”NATIONAL..." í˜•íƒœ
    # ëŒ€ì‹œ(-)ê°€ ì—¬ëŸ¬ ì¢…ë¥˜ì¼ ìˆ˜ ìˆì–´ì„œ \Wë¡œ ì²˜ë¦¬
    match_title = re.search(r'Title\s+\d+\W+([A-Z\s\-\,]+)', text)
    if match_title:
        title_candidate = match_title.group(1).strip()
        # ì œëª©ì´ 5ì ì´ìƒ, 100ì ë¯¸ë§Œì¼ ê²½ìš° ì±„íƒ
        if 5 < len(title_candidate) < 100:
            return title_candidate

    # íŒ¨í„´ 2: "cited as"
    match_cited = re.search(r'cited as the\s+["\']([^"\']{3,100})["\']', text, re.IGNORECASE)
    if match_cited: return clean_text(match_cited.group(1))
    
    # íŒ¨í„´ 3: ì²« ì¤„ì´ ëŒ€ë¬¸ì ë©ì–´ë¦¬ì¸ ê²½ìš°
    first_line = text.split('\n')[0].strip()
    if first_line.isupper() and len(first_line) > 5:
        # Act, Code, Program ë“±ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì œëª©ìœ¼ë¡œ ê°„ì£¼
        if any(k in first_line for k in ["ACT", "CODE", "PROGRAM", "LAW"]):
            return first_line

    return None

def is_historical_noise(text):
    """ì—­ì‚¬ ì‚¬ë£Œ í•„í„°"""
    preview = text[:500].lower()
    noise_keywords = [
        "john adams", "abigail adams", "george washington", "letter to", 
        "diary of", "obidient servant"
    ]
    return any(k in preview for k in noise_keywords)

def split_into_articles(text):
    chunks = []
    # íŒ¨í„´: Section ê¸°í˜¸(Â§), Sec., Section, ë˜ëŠ” Article
    pattern = r'((?:Section|Sec\.|Â§|Article)\s*\d+[a-zA-Z0-9\(\)\-]*)'
    
    parts = re.split(pattern, text)
    
    curr_art = "Preamble" # ì¡°í•­ ë²ˆí˜¸ê°€ ì—†ëŠ” ì•ë¶€ë¶„
    
    for p in parts:
        p = p.strip()
        if not p: continue
        
        # ì¡°í•­ ë²ˆí˜¸ì¸ì§€ í™•ì¸
        if re.match(pattern, p): 
            curr_art = p
        else:
            # ë‚´ìš© ë¶€ë¶„ ì²˜ë¦¬
            cleaned_content = clean_text(p)
            if cleaned_content:
                chunks.append({"article_no": curr_art, "content": cleaned_content})
    
    # ë§Œì•½ ìª¼ê°œì§„ ê²Œ ì—†ëŠ”ë° ë‚´ìš©ì´ ìˆë‹¤ë©´ í†µì§¸ë¡œ ì €ì¥
    if not chunks and clean_text(text): 
        chunks.append({"article_no": "Full Text", "content": clean_text(text)})
        
    return chunks

def save_data(data):
    rows = []
    text = data['text']
    country = data['country']
    
    # ì œëª© ì¶”ì¶œ ì‹œë„
    title = get_title(text)
    
    # ì œëª©ì„ ëª» ì°¾ì•˜ìœ¼ë©´ "US Code Title [ìˆ«ì]" í˜•ì‹ìœ¼ë¡œ ì €ì¥
    if not title and country == 'US':
        match_num = re.search(r'Title\s+(\d+)', text)
        if match_num:
            title = f"US Code Title {match_num.group(1)}"
        else:
            title = "US Federal Law"
    elif not title:
        title = f"{country} Legal Document"

    # ë³¸ë¬¸ ì²­ì†Œ
    cleaned_full_text = clean_text(text)
    
    # ì „ì²˜ë¦¬ í›„ ë‚´ìš© ë¹„ì–´ìˆìœ¼ë©´ ì €ì¥X
    if not cleaned_full_text:
        return []

    for chunk in split_into_articles(cleaned_full_text):
        rows.append({
            "country_id": COUNTRY_MAP[country],
            "law_title": clean_text(title),
            "category": "Statute",
            "article_no": clean_text(chunk['article_no']),
            "content": clean_text(chunk['content']),
            "enactment_date": "2020-01-01",
            "amendment_date": "2024-01-01"
        })
    return rows

def main():
    final_data = []
    print("ë²•ë¥  ë°ì´í„° ì •ì œ ë° ìˆ˜ì§‘ V2.0")

    # 1. ë¯¸êµ­ ë°ì´í„° (pile-of-law / uscode)
    print("\nğŸ‡ºğŸ‡¸ [US] ìˆ˜ì§‘ ì¤‘...")
    try:
        us_ds = load_dataset("pile-of-law/pile-of-law", "uscode", split="train", streaming=True, trust_remote_code=True)
        count = 0
        for item in us_ds:
            if count >= TARGET_PER_COUNTRY: break
            if len(item['text']) < 200: continue # ë„ˆë¬´ ì§§ì€ ê±´ ë²„ë¦¼
            
            rows = save_data({'text': item['text'], 'country': 'US'})
            final_data.extend(rows)
            count += 1
            if count % 50 == 0: 
                print(f"   Running... {count} (Sample Title: {rows[0]['law_title']})")
    except Exception as e: print(f"US Error: {e}")

    # 2. ìºë‚˜ë‹¤ ë°ì´í„° (Multi_Legal_Pile)
    print("\nğŸ‡¨ğŸ‡¦ [CA] ìˆ˜ì§‘ ì¤‘...")
    try:
        ca_ds = load_dataset("joelniklaus/Multi_Legal_Pile", "en_legislation", split="train", streaming=True, trust_remote_code=True)
        ca_ds = ca_ds.shuffle(seed=42, buffer_size=30000)
        
        count = 0
        for item in ca_ds:
            if count >= TARGET_PER_COUNTRY: break
            
            text = item.get('text', '')
            jurisdiction = str(item.get('jurisdiction', '')).upper()
            
            # ìºë‚˜ë‹¤ + ì—­ì‚¬ í¸ì§€ ì•„ë‹˜
            if ("CANADA" in jurisdiction or "CA" in jurisdiction) and not is_historical_noise(text):
                rows = save_data({'text': text, 'country': 'CA'})
                final_data.extend(rows)
                count += 1
                if count % 50 == 0: 
                    print(f"   Running... {count} (Sample Title: {rows[0]['law_title']})")

    except Exception as e: print(f"CA Error: {e}")

    print(f"\nì €ì¥ ì¤‘... ì´ {len(final_data)}ê°œ í–‰")
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)
    print("ì™„ë£Œ!")

if __name__ == "__main__":
    main()
    