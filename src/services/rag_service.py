import os
from typing import List, Dict, Any
import vertexai
from vertexai.language_models import TextEmbeddingModel, TextEmbeddingInput
from vertexai.generative_models import GenerativeModel
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from src.core.models import Law
from src.core.config import settings
from sqlalchemy import select, label  # ê±°ë¦¬ ê³„ì‚° ì¶”ê°€ ì½”ë“œ


# ëª¨ë¸ ë¡œë“œ (í•¨ìˆ˜ í˜¸ì¶œ ì‹œë§ˆë‹¤ ë¡œë“œí•˜ì§€ ì•Šë„ë¡ ì „ì—­ ë³€ìˆ˜ ì²˜ë¦¬ ê³ ë ¤ ê°€ëŠ¥)
def get_models():
    # GCP í”„ë¡œì íŠ¸ ì„¤ì •
    vertexai.init(project=settings.GCP_PROJECT_ID, location=settings.GCP_LOCATION)

    # ëª¨ë¸ ë¡œë“œ
    embedding_model = TextEmbeddingModel.from_pretrained("text-embedding-005")
    # settingsì— ëª¨ë¸ëª…ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
    model_name = settings.GCP_MODEL_NAME or "gemini-1.5-flash-001"
    generative_model = GenerativeModel(model_name)

    return embedding_model, generative_model


async def generate_answer(query: str, db: AsyncSession) -> Dict[str, Any]:
    embedding_model, generative_model = get_models()

    # 1. [ì„ë² ë”©] ì§ˆë¬¸ì„ ë²¡í„°ë¡œ ë³€í™˜
    try:
        text_input = TextEmbeddingInput(text=query, task_type="RETRIEVAL_QUERY")
        embeddings = embedding_model.get_embeddings([text_input])
        query_vector = embeddings[0].values
    except Exception as e:
        print(f"âŒ ì„ë² ë”© ì‹¤íŒ¨: {e}")
        raise e

    # 2. [ê²€ìƒ‰] DBì—ì„œ ìœ ì‚¬í•œ ë²•ë¥  ì¡°í•­ 1ê°œ ì°¾ê¸°
    # l2_distance (ìœ í´ë¦¬ë“œ ê±°ë¦¬) ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    stmt = select(
        Law, Law.embedding.l2_distance(query_vector).label("distance")
    ).order_by(
        Law.embedding.l2_distance(query_vector)
    )  # .limit(1) ì œì™¸(ê±°ë¦¬ ê³„ì‚° ì¶”ê°€ ì½”ë“œ)
    if law.country_code:  # ì‚¬ìš©ìê°€ "KR"ì„ ì„ íƒí–ˆê±°ë‚˜ ì§ˆë¬¸ì—ì„œ ì¶”ì¶œí–ˆë‹¤ë©´
        stmt = stmt.where(
            Law.country_code == law.country_code
        )  # â˜… í•µì‹¬: í•œêµ­ ë²•ë§Œ ë‚¨ê¹€!
    result = await db.execute(stmt)
    rows = result.all()  # ê±°ë¦¬ ê³„ì‚° ì¶”ê°€ ì½”ë“œ
    # laws = result.scalars().all() : ê±°ë¦¬ ê³„ì‚° ì½”ë“œë¥¼ ìœ„í•´ ì‚­ì œ

    # ---------------------------------------------------------
    # ğŸ“Š [ë¡œê·¸ ì¶œë ¥] ì—¬ê¸°ì„œ ì ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”!
    # ---------------------------------------------------------
    print(f"\nğŸ” [ìœ ì‚¬ë„ ì¸¡ì •] ì§ˆë¬¸: '{query}'")
    print("=" * 60)
    for i, row in enumerate(rows):
        law = row[0]
        distance = row[1]
        print(f"{i+1}. ê±°ë¦¬: {distance:.5f} | {law.law_title} {law.article_no}")
        print(f"   ë‚´ìš©: {law.content[:30]}...")  # ë‚´ìš©ë„ ë³´ê³  ì‹¶ìœ¼ë©´ ì£¼ì„ í•´ì œ
    print("=" * 60 + "\n")
    # ---------------------------------------------------------

    # 3. [ë¡œì§] ì¼ë‹¨ ê°€ì¥ ê°€ê¹Œìš´(0ë²ˆ) 1ê°œë§Œ ì„ íƒí•´ì„œ ë‹µë³€ ìƒì„±
    # (ë‚˜ì¤‘ì— ì—¬ê¸°ì„œ Threshold ë¡œì§ì„ ì ìš©í•˜ë©´ ë©ë‹ˆë‹¤)

    if not rows:
        return {
            "answer": "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.",
            "related_law_id_list": [],
            "search_success": False,
        }

    # ê°€ì¥ ê°€ê¹Œìš´ 1ê°œ ì„ íƒ
    top_law = rows[0][0]
    top_distance = rows[0][1]

    # 4. [í”„ë¡¬í”„íŠ¸]
    context_text = f"- [{top_law.law_title} {top_law.article_no}]: {top_law.content}\n"
    law_ids = [top_law.law_id]

    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (í˜ë¥´ì†Œë‚˜ + ê°€ë“œë ˆì¼)
    prompt = f"""
    ë‹¹ì‹ ì€ 'Global Legal Assistant'ë¼ëŠ” ì „ë¬¸ ë²•ë¥  ë¹„ì„œì…ë‹ˆë‹¤.
    ë°˜ë“œì‹œ ì•„ë˜ ì œê³µëœ [ê·¼ê±° ìë£Œ]ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
    
    [ì§€ì‹œ ì‚¬í•­]
    1. ë‹µë³€ì€ ë°˜ë“œì‹œ [ê·¼ê±° ìë£Œ]ì— ëª…ì‹œëœ ë‚´ìš©ìœ¼ë¡œë§Œ êµ¬ì„±í•˜ì„¸ìš”. (í™˜ê° ë°©ì§€)
    2. [ê·¼ê±° ìë£Œ]ì™€ ê´€ë ¨ ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
    3. ë§Œì•½ [ê·¼ê±° ìë£Œ]ë¡œ ë‹µí•  ìˆ˜ ì—†ë‹¤ë©´, "ì£„ì†¡í•©ë‹ˆë‹¤. ì œê³µëœ ì •ë³´ë§Œìœ¼ë¡œëŠ” ë‹µë³€í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤."ë¼ê³ ë§Œ ë§í•˜ì„¸ìš”.
    4. ë‹µë³€ì€ ì¹œì ˆí•˜ê³  ëª…í™•í•œ ì „ë¬¸ê°€ì˜ ì–´ì¡°(~ì…ë‹ˆë‹¤)ë¡œ ì‘ì„±í•˜ì„¸ìš”.

    [ê·¼ê±° ìë£Œ]
    {context_text}

    [ì‚¬ìš©ì ì§ˆë¬¸]
    {query}

    [ë‹µë³€]
    """

    # 5. [ìƒì„±] Geminiì—ê²Œ ë‹µë³€ ìš”ì²­
    try:
        response = generative_model.generate_content(prompt)
        final_answer = response.text
    except Exception as e:
        print(f"âŒ Gemini í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        final_answer = "AI ëª¨ë¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    # 6. ê²°ê³¼ ë°˜í™˜
    return {
        "answer": final_answer,
        "related_law_id_list": law_ids,
        "search_success": True,
    }
