# src/services/rag_service.py
import os
from typing import List, Dict, Any
import vertexai
from vertexai.language_models import TextEmbeddingModel, TextEmbeddingInput
from vertexai.generative_models import GenerativeModel, GenerationConfig
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, label
from src.core.models import Law, Country
from src.core.config import settings

# Top-K ì„¤ì •: ê°€ì¥ ìœ ì‚¬í•œ ë²•ë¥  3ê°œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤
TOP_K = 3

# ì„ê³„ê°’ ì„¤ì •: ê±°ë¦¬(Distance)ê°€ 0.95 ì´í•˜ì¸ ë¬¸ì„œë§Œ ì°¸ê³ í•©ë‹ˆë‹¤.
# (0.95ë³´ë‹¤ í¬ë©´ ê´€ë ¨ì„±ì´ ì—†ë‹¤ê³  íŒë‹¨í•˜ì—¬ ë²„ë¦½ë‹ˆë‹¤.)
MAX_DISTANCE_THRESHOLD = 0.95


# ëª¨ë¸ ë¡œë“œ (í•¨ìˆ˜ í˜¸ì¶œ ì‹œë§ˆë‹¤ ë¡œë“œí•˜ì§€ ì•Šë„ë¡ ì „ì—­ ë³€ìˆ˜ ì²˜ë¦¬ ê³ ë ¤ ê°€ëŠ¥)
def get_models():

    # GCP í”„ë¡œì íŠ¸ ì„¤ì •
    # settings.GCP_PROJECT_IDì™€ settings.GCP_LOCATIONì€ .envì—ì„œ ì½ì–´ì˜´
    vertexai.init(project=settings.GCP_PROJECT_ID, location=settings.GCP_LOCATION)

    # ëª¨ë¸ ë¡œë“œ
    embedding_model = TextEmbeddingModel.from_pretrained("text-embedding-005")
    model_name = settings.GCP_MODEL_NAME
    generative_model = GenerativeModel(model_name)

    return embedding_model, generative_model


async def generate_answer(
    query: str, db: AsyncSession, country_id: int
) -> Dict[str, Any]:
    embedding_model, generative_model = get_models()

    # 0. [ì „ì²˜ë¦¬] êµ­ê°€ ì½”ë“œ
    target_country_id = country_id

    print(f"ğŸŒ êµ­ê°€ í•„í„°ë§ ì ìš©: ID {country_id}")

    # 1. [ì„ë² ë”©] ì§ˆë¬¸ì„ ë²¡í„°ë¡œ ë³€í™˜
    try:
        text_input = TextEmbeddingInput(text=query, task_type="RETRIEVAL_QUERY")
        embeddings = embedding_model.get_embeddings([text_input])
        query_vector = embeddings[0].values
    except Exception as e:
        print(f"âŒ ì„ë² ë”© ì‹¤íŒ¨: {e}")
        # Vertex AI í†µì‹  ì˜¤ë¥˜ê°€ ì—¬ê¸°ì„œ ë°œìƒí•  ê°€ëŠ¥ì„±ì´ ë†’ìŒ
        raise e

    # 2. [ê²€ìƒ‰] DBì—ì„œ ìœ ì‚¬í•œ ë²•ë¥  ì¡°í•­ Top-Kê°œ ì°¾ê¸°
    # Law ëª¨ë¸ì—ëŠ” embedding ì»¬ëŸ¼ì´ pgvector.sqlalchemy.Vector íƒ€ì…ì´ë¼ê³  ê°€ì •
    # ê¸°ë³¸ ì¿¼ë¦¬: Law í…Œì´ë¸”ê³¼ ê±°ë¦¬ ê³„ì‚°
    stmt = (
        select(Law, Law.embedding.l2_distance(query_vector).label("distance"))
        .where(Law.country_id == target_country_id)
        .order_by(Law.embedding.l2_distance(query_vector))
        .limit(TOP_K)
    )

    result = await db.execute(stmt)
    rows = result.all()

    valid_docs = []
    related_ids = []

    # ê²€ìƒ‰ëœ ëª¨ë“  í–‰(row)ì„ ê²€ì‚¬
    for row in rows:
        law = row[0]
        distance = row[1]

        # ì„ê³„ê°’(0.95) ì´ë‚´ì¸ ê²½ìš°ë§Œ ìœ íš¨í•œ ë¬¸ì„œë¡œ ì¸ì •
        if distance <= MAX_DISTANCE_THRESHOLD:
            valid_docs.append(law)
            related_ids.append(law.law_id)

    # ìœ íš¨í•œ ë¬¸ì„œê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ë°”ë¡œ ë°˜í™˜ (Gemini í˜¸ì¶œ X)
    if not valid_docs:
        return {
            "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸í•˜ì‹  ë‚´ìš©ê³¼ ê´€ë ¨ëœ ì •í™•í•œ ë²•ë¥  ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ê´€ë ¨ë„ ë‚®ìŒ)",
            "related_law_id_list": [],
            "search_success": False,
        }

    # ì—¬ëŸ¬ ê°œì˜ ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ ì»¨í…ìŠ¤íŠ¸ë¡œ í•©ì¹˜ê¸°
    context_text = ""
    for law in valid_docs:
        context_text += f"""
        [ë¬¸ì„œ ID: {law.law_id}]
        - ë²•ë¥ ëª…: {law.law_title}
        - ì¡°í•­: {law.article_no}
        - ë‚´ìš©: {law.content}
        --------------------------------------------------
        """

    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (í˜ë¥´ì†Œë‚˜ + ê°€ë“œë ˆì¼)
    prompt = f"""
    ë‹¹ì‹ ì€ 'Global Legal Assistant'ì…ë‹ˆë‹¤. 
    ì „ ì„¸ê³„ ë²•ë¥  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ë²•ë¥  AI ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    
    ë°˜ë“œì‹œ ì•„ë˜ ì œê³µëœ [ê·¼ê±° ìë£Œ]ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ì‘ì„±í•˜ì‹­ì‹œì˜¤. ì™¸ë¶€ ì§€ì‹ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.

    [ê·¼ê±° ìë£Œ]
    {context_text}

    [ì‚¬ìš©ì ì§ˆë¬¸]
    {query}

    [ë‹µë³€ ì‘ì„± ê°€ì´ë“œë¼ì¸]
    1. **ê´€ë ¨ì„± ìµœìš°ì„  (ì¤‘ìš”):** ê°€ì¥ ë¨¼ì € [ê·¼ê±° ìë£Œ]ê°€ [ì‚¬ìš©ì ì§ˆë¬¸]ì˜ ì£¼ì œ(êµ­ê°€, ë²•ë¥  ëŒ€ìƒ, ìƒí™©)ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ íŒë‹¨í•˜ì‹­ì‹œì˜¤.
    2. **ë¬´ê´€í•œ ìë£Œ ë¬´ì‹œ:** ë§Œì•½ [ê·¼ê±° ìë£Œ]ê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ì—†ë‹¤ë©´(ì˜ˆ: íƒœêµ­ ë²•ë¥  ì§ˆë¬¸ì— í•œêµ­ ë²•ë¥  ìë£Œê°€ ì£¼ì–´ì§„ ê²½ìš°), ì ˆëŒ€ ê·¼ê±° ìë£Œ ë‚´ìš©ì„ ìš”ì•½í•˜ê±°ë‚˜ ì„¤ëª…í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
    3. **ë‹µë³€ ë¶ˆê°€ ì²˜ë¦¬:** ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ [ê·¼ê±° ìë£Œ]ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ **"ì£„ì†¡í•©ë‹ˆë‹¤. ì œê³µëœ ì •ë³´ë§Œìœ¼ë¡œëŠ” ë‹µë³€í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤."**ë¼ê³ ë§Œ ë‹µë³€í•˜ì‹­ì‹œì˜¤.
    4. **í•µì‹¬ ìš”ì•½:** ë‹µë³€ì´ ê°€ëŠ¥í•œ ê²½ìš°, ì¥í™©í•˜ê²Œ ì„¤ëª…í•˜ì§€ ë§ê³  í•µì‹¬ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ì‹­ì‹œì˜¤.
    5. **ë¶„ëŸ‰ ì œí•œ:** ì „ì²´ ë‹µë³€ ê¸¸ì´ëŠ” **3~5ë¬¸ì¥ ë‚´ì™¸**ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤. (ê°€ë…ì„± ì¤‘ì‹œ)
    6. **ê·¼ê±° ì¤‘ì‹¬:** ë‹µë³€ì˜ ëª¨ë“  ë‚´ìš©ì€ ìœ„ [ê·¼ê±° ìë£Œ]ì— ìˆëŠ” ë‚´ìš©ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆì‹­ì‹œì˜¤.
    7. **ë³¸ë¬¸ ë‚´ ì¸ìš©:** ë³„ë„ì˜ ì¶œì²˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ì§€ ë§ê³ , ë‹µë³€ ë¬¸ì¥ ì†ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ê·¼ê±°ë¥¼ ë°íˆì‹­ì‹œì˜¤. (ì˜ˆ: "ë„ë¡œêµí†µë²• ì œ44ì¡°ì— ë”°ë¥´ë©´...")
    8. **ë…¼ë¦¬ì  ì¢…í•©:** ì—¬ëŸ¬ ë²•ë¥  ì¡°í•­ì´ ìˆë‹¤ë©´ ì´ë¥¼ ì¢…í•©í•˜ì—¬ í•˜ë‚˜ì˜ ê²°ë¡ ìœ¼ë¡œ ë„ì¶œí•˜ì‹­ì‹œì˜¤.
    9. **ì–¸ì–´:** ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ í•œêµ­ì–´ë¼ë©´, ê·¼ê±° ìë£Œê°€ ì˜ì–´ì¼ì§€ë¼ë„ ë°˜ë“œì‹œ **ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´**ë¡œ ë²ˆì—­í•˜ì—¬ ë‹µë³€í•˜ì‹­ì‹œì˜¤.
    10. **ë©´ì±… ì¡°í•­:** ë‹µë³€ì„ ì œê³µí•œ ê²½ìš°ì—ë§Œ ë§ˆì§€ë§‰ì— ì¤„ì„ ë°”ê¾¸ê³  "â€» ë³¸ ë‹µë³€ì€ ë²•ë¥ ì  ì¡°ì–¸ì´ ì•„ë‹ˆë©° ì •ë³´ ì œê³µì„ ëª©ì ìœ¼ë¡œ í•©ë‹ˆë‹¤."ë¼ëŠ” ë¬¸êµ¬ë¥¼ í¬í•¨í•˜ì‹­ì‹œì˜¤. (ë‹µë³€ ë¶ˆê°€ ì‹œì—ëŠ” ìƒëµ)

    [ë‹µë³€ í˜•ì‹]
    - **ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ìˆëŠ” ê²½ìš°:**
        - **ê²°ë¡ :** (ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ 1ë¬¸ì¥ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ì œì‹œ)
        - **ìƒì„¸ ë‚´ìš©:** (ë²•ë¥  ì¡°í•­ì„ ê·¼ê±°ë¡œ í•µì‹¬ ë‚´ìš©ì„ 2~4ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½ ì„¤ëª…)
    
    - **ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ì—†ëŠ” ê²½ìš°:**
        "ì£„ì†¡í•©ë‹ˆë‹¤. ì œê³µëœ ì •ë³´ë§Œìœ¼ë¡œëŠ” ë‹µë³€í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤."
    """

    # 5. [ìƒì„±] Geminiì—ê²Œ ë‹µë³€ ìš”ì²­
    try:
        # LLM ìƒì„± íŒŒë¼ë¯¸í„° ì„¤ì •
        config = GenerationConfig(
            temperature=0.0,  # temperature : 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê°€ì¥ í™•ë¥  ë†’ì€ ë‹¨ì–´ë¥¼ ì„ íƒí•˜ì—¬ ë‹µë³€ì´ ë…¼ë¦¬ì ì´ê³  ì •í•´ì§„ í‹€ì„ ë”°ë¦…ë‹ˆë‹¤.
            max_output_tokens=1024,  # max_output_tokens : ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜ (ì•½ 700~800ë‹¨ì–´ ë¶„ëŸ‰)
            top_k=20,  # top_k : ìƒìœ„ 20ê°œ ë‹¨ì–´ë§Œ í›„ë³´ë¡œ ë‘  (ì´ìƒí•œ ë‹¨ì–´ ì°¨ë‹¨)
            top_p=0.7,  # top_p : ìƒìœ„ 70% í™•ë¥  ë‚´ì—ì„œë§Œ ì„ íƒ (ì‹ ë¢°ë„ í™•ë³´)
        )
        response = generative_model.generate_content(prompt, generation_config=config)
        final_answer = response.text
    except Exception as e:
        print(f"âŒ Gemini í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        raise e  # ì—ëŸ¬ë¥¼ ë‹¤ì‹œ ë˜ì ¸ì„œ API ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ í•¨

    # 6. ê²°ê³¼ ë°˜í™˜
    return {
        "answer": final_answer,
        "related_law_id_list": related_ids,
        "search_success": True,
    }
